---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

<br><br>
# üëÄ About Me

Hi,

[cite_start]üå± I‚Äôm **Hui Huang**, a Ph.D. student at Harbin Institute of Technology in Computer Science[cite: 7]. [cite_start]I am supervised by Professor Muyun Yang[cite: 7].

üìñ My research interest includes:
  - [cite_start]Large Language Models (LLM) [cite: 8]
  - [cite_start]Natural Language Processing (NLP) [cite: 8]

[cite_start]üì´ Feel free to contact me via email: 22b903058@stu.hit.edu.cn[cite: 2].

<br><br>
# üî• News
- *2024.10*: &nbsp; [cite_start]Our paper **2D-DPO** was released on Arxiv[cite: 33].
- *2024.11*: &nbsp; [cite_start]Delighted to announce that **Self-Evaluation of Large Language Model based on Glass-box Features** was accepted by Findings of EMNLP 2024[cite: 36].
- *2024.07*: &nbsp; [cite_start]Started Research Internship at Future Life Laboratory, Alibaba Group[cite: 16, 19]. [cite_start]My research centers on the improvement of video understanding LLM[cite: 20].
- *2024.03*: &nbsp; [cite_start]Our paper **An Empirical Study of LLM-as-a-Judge for LLM Evaluation** was released on Arxiv[cite: 34].
- *2024.02*: &nbsp; [cite_start]Our paper **Multi-view fusion for instruction mining of large language model** was published in Information Fusion[cite: 41, 42].
- *2023.07*: &nbsp; [cite_start]Our paper **Improving Translation Quality Estimation with Bias Mitigation** was accepted by ACL 2023[cite: 44, 46, 47]!

<br><br>
# üìù Publications

<div class='paper-box'>
<div class='paper-box-text' markdown="1">

[2D-DPO: Scaling Direct Preference Optimization with 2-Dimensional Supervision](https://arxiv.org/abs/2410.19720)

S. Li*, Y. He*, **H. [cite_start]Huang***, X. Bu, J. Liu, H. Guo, W. Wang, J. Gu, W. Su, and B. Zheng [cite: 33]

</div>
</div>

<div class='paper-box'>
<div class='paper-box-text' markdown="1">

[Self-evaluation of large language model based on glass-box features](https://aclanthology.org/2024.findings-emnlp.XXX/) *(placeholder link)*

**H. [cite_start]Huang**, Y. Qu, J. Liu, M. Yang, B. Xu, T. Zhao, and W. Lu [cite: 36]

</div>
</div>

<div class='paper-box'>
<div class='paper-box-text' markdown="1">

[An empirical study of Ilm-as-a-judge for llm evaluation: Fine-tuned judge model is not a general substitute for gpt-4](https://arxiv.org/abs/2403.02839)

**H. [cite_start]Huang**, Y. Qu, X. Bu, H. Zhou, J. Liu, M. Yang, B. Xu, and T. Zhao [cite: 34]

</div>
</div>

<div class='paper-box'>
<div class='paper-box-text' markdown="1">

[Migitating the bias of large language model evaluation](https://aclanthology.org/2024.ccl-1.XXX/) *(placeholder link)*

H. Zhou, **H. [cite_start]Huang**, Y. Long, B. Xu, C. Zhu, H. Cao, M. Yang, and T. Zhao [cite: 38, 39, 40]

</div>
</div>

<div class='paper-box'>
<div class='paper-box-text' markdown="1">

[Multi-view fusion for instruction mining of large language model](https://doi.org/10.1016/j.inffus.2024.102480)

**H. [cite_start]Huang**, B. Xu, X. Liang, K. Chen, M. Yang, T. Zhao, and C. Zhu [cite: 41, 42]

</div>
</div>

<div class='paper-box'>
<div class='paper-box-text' markdown="1">

[Improving translation quality estimation with bias mitigation](https://aclanthology.org/2023.acl-long.155/)

**H. [cite_start]Huang**, S. Wu, K. Chen, H. Di, M. Yang, and T. Zhao [cite: 44, 46, 47]

</div>
</div>

<div class='paper-box'>
<div class='paper-box-text' markdown="1">

[Iterative nearest neighbour machine translation for unsupervised domain adaptation](https://aclanthology.org/2023.findings-acl.844/)

**H. [cite_start]Huang**, S. Wu, X. Liang, Z. Zhou, M. Yang, and T. Zhao [cite: 48]

</div>
</div>

<div class='paper-box'>
<div class='paper-box-text' markdown="1">

[Multi-view fusion for universal translation quality estimation](https://doi.org/10.1016/j.inffus.2023.102022)

**H. [cite_start]Huang**, S. Wu, K. Chen, X. Liang, H. Di, M. Yang, and T. Zhao [cite: 49, 50]

</div>
</div>

<div class='paper-box'>
<div class='paper-box-text' markdown="1">

[Towards making the most of Ilm for translation quality estimation](https://doi.org/10.1007/978-3-031-44693-1_30)

**H. [cite_start]Huang**, S. Wu, X. Liang, B. Wang, Y. Shi, P. Wu, M. Yang, and T. Zhao [cite: 51, 52, 53]

</div>
</div>

<div class='paper-box'>
<div class='paper-box-text' markdown="1">

[BJTU-toshiba's submission to WMT22 quality estimation shared task](https://aclanthology.org/2022.wmt-1.80/)

**H. [cite_start]Huang**, H. Di, C. Li, H. Wu, K. Ouchi, Y. Chen, J. Liu, and J. Xu [cite: 54, 55, 60, 61]

</div>
</div>

<div class='paper-box'>
<div class='paper-box-text' markdown="1">

[Iterative constrained back-translation for unsupervised domain adaptation of machine translation](https://aclanthology.org/2022.coling-1.442/)

H. Zhang, **H. [cite_start]Huang**, J. Gao, Y. Chen, J. Xu, and J. Liu [cite: 56, 57, 62, 63]

</div>
</div>

<div class='paper-box'>
<div class='paper-box-text' markdown="1">

[Multi-source inverse-curriculum-based training for low-resource dialogue generation](https://doi.org/10.1007/s10489-022-04190-z)

F. Cui, H. Di, **H. [cite_start]Huang**, H. Ren, K. Ouchi, Z. Liu, and J. Xu [cite: 58, 59, 64, 65]

</div>
</div>

<div class='paper-box'>
<div class='paper-box-text' markdown="1">

[Saliency-based multi-view mixed language training for zero-shot cross-lingual classification](https://aclanthology.org/2021.findings-emnlp.51/)

S. Lai, **H. [cite_start]Huang**, D. Jing, Y. Chen, J. Xu, and J. Liu [cite: 66]

</div>
</div>

<div class='paper-box'>
<div class='paper-box-text' markdown="1">

[Contrastive learning for machine translation quality estimation](https://doi.org/10.1007/978-3-030-88480-2_8)

**H. [cite_start]Huang**, H. Di, J. Liu, Y. Chen, K. Ouchi, and J. Xu [cite: 67, 68]

</div>
</div>

<div class='paper-box'>
<div class='paper-box-text' markdown="1">

[Ensemble distilling pretrained language models for machine translation quality estimation](https://doi.org/10.1007/978-3-030-60457-8_19)

**H. [cite_start]Huang**, H. Di, J. Xu, K. Ouchi, and Y. Chen [cite: 69, 70]

</div>
</div>

<br><br>
# üíª Experiences
- [cite_start]*2024.07 - Present*, Research Internship Future Life Laboratory, Alibaba Group[cite: 16, 19]. [cite_start]My research centers on the improvement of video understanding LLM[cite: 20].
- [cite_start]*2023.09 - 2024.03*, Research Internship Department of Wenxin Yiyan, Baidu Inc.[cite: 17, 21]. [cite_start]My research centers on the improvement and evaluation of large language model[cite: 22].
- [cite_start]*2023.03 - 2023.08*, Research Internship AI Lab, ByteDance Inc.[cite: 18, 23]. [cite_start]My research centers on the improvement and applications of large language model[cite: 24].
- [cite_start]*2022.10 - 2023.03*, Research Internship Lark AI, ByteDance Inc.[cite: 26]. [cite_start]My research centers on pre-trained model and machine translation[cite: 25].
- [cite_start]*2019.07 - 2022.08*, Research Internship Toshiba Research and Development Center[cite: 27]. [cite_start]My research centers on machine translation and dialogue system[cite: 28].

<br><br>
# üìù Academic Service (Reviewer)
- Currently, no reviewer information is available in the provided CV.

<br><br>
# üéñ Honors and Awards
- [cite_start]*2023*: CHIP Shared Task, Ranked 1st on No-Finetuning Track[cite: 81].
- [cite_start]*2023*: Eval4NLP Shared Task, Ranked 1st on Medium-Sized Track[cite: 81].
- [cite_start]*2022*: WMT Shared Task, Ranked 2nd on Quality Estimation for En-De Tracks[cite: 81].
- [cite_start]*2021*: CCMT Shared Task, Ranked 1st on Quality Estimation and Automatic Post-Editing for Zh-En and Machine Translation for Zh-En, En-Zh and Ti-Zh Tracks[cite: 81].
- [cite_start]*2020*: CCMT Shared Task, Ranked 1st on Quality Estimation for both Zh-En and En-Zh Tracks[cite: 81].

<br><br>
# üìñ Educations
- [cite_start]*2022.08 - Present*, Ph.D., Harbin Institute of Technology in Computer Science[cite: 6, 7]. [cite_start]Supervised by Professor Muyun Yang[cite: 7].
- [cite_start]*2018.09 - 2022.06*, M.Sc., Beijing Jiaotong University in Computer Science[cite: 9, 10]. [cite_start]Supervised by Professor Jin'an Xu[cite: 11]. [cite_start]Thesis title: Pre-trained Model based Machine Translation Quality Estimation[cite: 13].
- [cite_start]*2014.09 - 2018.06*, B.Sc., University of Science and Technology Beijing in Computer Science[cite: 12, 13]. [cite_start]Thesis title: Japanese Word Segmentation with Lexical Knowledge Augmentation[cite: 14].